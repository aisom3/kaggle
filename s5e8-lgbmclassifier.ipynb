{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91719,"databundleVersionId":12937777,"sourceType":"competition"},{"sourceId":9293783,"sourceType":"datasetVersion","datasetId":5626665}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install Optuna\n!pip install optuna --quiet\n!pip install optuna-integration[lightgbm] --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T15:59:15.772117Z","iopub.execute_input":"2025-08-15T15:59:15.772389Z","iopub.status.idle":"2025-08-15T15:59:24.524843Z","shell.execute_reply.started":"2025-08-15T15:59:15.772367Z","shell.execute_reply":"2025-08-15T15:59:24.523678Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Approach\n- Implement [LightGBM](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html)\n- Tune and train LightGBM using Optuna, testing different imbalanced techniques using train, original, and test data sets.\n- Implement label encoding for train and test.\n- Evaluate each model using cross-validation with ROC AUC.\n- Train on all training data and predict probabilities for the test set.\n\n### Results\n- Local CV results range from 0.971 to 0.973 with a leaderboard score of 0.975.\n\n### Todo\n- Run more tuning tests.","metadata":{}},{"cell_type":"code","source":"# Author: Aaron Isom\n# Kaggle Playground-Series-S5e8 - Binary Classification with a Bank Dataset\n\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import roc_auc_score\nfrom optuna.samplers import TPESampler\nfrom optuna.integration import LightGBMPruningCallback\n\nimport lightgbm as lgb\nimport numpy as np\nimport pandas as pd\nimport warnings\nimport optuna\n\nwarnings.filterwarnings('ignore')\ntune = False # Toggle for Optuna tuning and final submission\nrun_cv = True # Toggle for final model validation using best parameters","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-15T15:59:24.526649Z","iopub.execute_input":"2025-08-15T15:59:24.526991Z","iopub.status.idle":"2025-08-15T15:59:30.716565Z","shell.execute_reply.started":"2025-08-15T15:59:24.526954Z","shell.execute_reply":"2025-08-15T15:59:30.715567Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Optuna Tuning\ndef objective(trial):\n  \n    params = {\n        'boosting_type': 'gbdt',\n        'n_estimators': trial.suggest_int('n_estimators', 500, 25000),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n        'num_leaves': trial.suggest_int('num_leaves', 32, 128),\n        'max_depth': trial.suggest_int('max_depth', 4, 12),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 10),\n        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),\n        'max_bin': trial.suggest_int('max_bin', 512, 4096)\n    }\n      \n    #scale_pos_weight = len(y[y == 0]) / len(y[y == 1])\n    model = lgb.LGBMClassifier(**params, objective='binary', metric='auc', is_unbalance=True, random_state=42, verbosity=-1)\n    # scale_pos_weight=scale_pos_weight) \n    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    \n    return cross_val_score(model, X, y, cv=cv, scoring='roc_auc').mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T15:59:30.717623Z","iopub.execute_input":"2025-08-15T15:59:30.718225Z","iopub.status.idle":"2025-08-15T15:59:30.725123Z","shell.execute_reply.started":"2025-08-15T15:59:30.718200Z","shell.execute_reply":"2025-08-15T15:59:30.724270Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load data\ntrain = pd.read_csv('/kaggle/input/playground-series-s5e8/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s5e8/test.csv')\noriginal = pd.read_csv('/kaggle/input/bank-marketing-dataset-full/bank-full.csv', delimiter=\";\")\nsubmission = pd.read_csv('/kaggle/input/playground-series-s5e8/sample_submission.csv')\n\noriginal['y'] = original['y'].map({'yes': 1, 'no': 0})\n\ntrain = pd.concat([train, original], axis=0, ignore_index=True)\n\n# Features for training - drop id and target\nX = train.drop(['id', 'y'], axis=1)\ny = train['y']\n\n# Features for test set drop id\nX_test = test.drop(['id'], axis=1)\n\n# Encode object and category columns to ensure unique values are mapped\nfor col in X.select_dtypes(include=['object', 'category']).columns:\n    le = LabelEncoder()\n    le.fit(list(X[col].astype(str)) + list(X_test[col].astype(str)))\n    X[col] = le.transform(X[col].astype(str))\n    X_test[col] = le.transform(X_test[col].astype(str))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T15:59:30.726567Z","iopub.execute_input":"2025-08-15T15:59:30.727022Z","iopub.status.idle":"2025-08-15T15:59:41.877394Z","shell.execute_reply.started":"2025-08-15T15:59:30.726994Z","shell.execute_reply":"2025-08-15T15:59:41.876568Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cross-validated LGBMClassifier\n\nif tune:\n    # Optuna Study\n    study = optuna.create_study(direction='maximize')\n    study.optimize(objective, n_trials=25, timeout=5400, show_progress_bar=True)\n    best_params = study.best_trial.params\n    print('Best Parameters:', best_params)\n    print('Best Trial:', study.best_trial)\n\nelse:\n    best_params = {\"n_estimators\": 15000, \"learning_rate\": 0.0395, \"min_child_samples\": 8,\n                   \"subsample\": 0.6, \"colsample_bytree\": 0.7, \"num_leaves\": 100, \"max_depth\": 7,\n                  \"max_bin\": 4500, \"reg_alpha\": 0.8, \"reg_lambda\": 3}\n\n        \nclf = lgb.LGBMClassifier(**best_params, objective='binary', metric='auc', random_state=42, verbosity=-1)\nclf.fit(X, y)\n\nif run_cv:\n    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    cv_scores = cross_val_score(clf, X, y, cv=cv, scoring='roc_auc')\n    \n    print(\"ROC AUC scores (CV):\", cv_scores)\n    print(\"Mean ROC AUC:\", np.mean(cv_scores))\n\npreds = clf.predict_proba(X_test)[:, 1] ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T15:59:41.878618Z","iopub.execute_input":"2025-08-15T15:59:41.878983Z","iopub.status.idle":"2025-08-15T17:17:48.561734Z","shell.execute_reply.started":"2025-08-15T15:59:41.878955Z","shell.execute_reply":"2025-08-15T17:17:48.560940Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Final submission\nsubmission['y'] = preds\nsubmission.to_csv('submission.csv', index=False)\ndisplay(submission)\nprint('Submission file saved.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T17:17:48.562735Z","iopub.execute_input":"2025-08-15T17:17:48.563095Z","iopub.status.idle":"2025-08-15T17:17:49.073601Z","shell.execute_reply.started":"2025-08-15T17:17:48.563050Z","shell.execute_reply":"2025-08-15T17:17:49.072660Z"}},"outputs":[],"execution_count":null}]}