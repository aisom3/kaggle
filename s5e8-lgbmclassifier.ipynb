{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91719,"databundleVersionId":12937777,"sourceType":"competition"},{"sourceId":9293783,"sourceType":"datasetVersion","datasetId":5626665}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install Optuna\n!pip install optuna --quiet\n!pip install optuna-integration[lightgbm] --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T17:11:11.792763Z","iopub.execute_input":"2025-08-08T17:11:11.793094Z","iopub.status.idle":"2025-08-08T17:11:21.286068Z","shell.execute_reply.started":"2025-08-08T17:11:11.793068Z","shell.execute_reply":"2025-08-08T17:11:21.284592Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.9/98.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### Approach\n- Implement [LightGBM](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html)\n- Tune and train LightGBM using Optuna, testing different imbalanced techniques using train, original, and test data sets.\n- Implement label encoding for train and test.\n- Evaluate each model using cross-validation with ROC AUC.\n- Train on all training data and predict probabilities for the test set.\n\n### Results\n- Local CV results range from 0.971 to 0.973 with a leaderboard score of 0.975.\n\n### Todo\n- Run more tuning tests.","metadata":{}},{"cell_type":"code","source":"# Author: Aaron Isom\n# Kaggle Playground-Series-S5e8 - Binary Classification with a Bank Dataset\n\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import roc_auc_score\nfrom optuna.samplers import TPESampler\nfrom optuna.integration import LightGBMPruningCallback\n\nimport lightgbm as lgb\nimport numpy as np\nimport pandas as pd\nimport warnings\nimport optuna\n\nwarnings.filterwarnings('ignore')\ntune = False # Toggle for Optuna tuning and Final Submission","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-08T17:11:21.288582Z","iopub.execute_input":"2025-08-08T17:11:21.289234Z","iopub.status.idle":"2025-08-08T17:11:27.441630Z","shell.execute_reply.started":"2025-08-08T17:11:21.289167Z","shell.execute_reply":"2025-08-08T17:11:27.440786Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Optuna Tuning\ndef objective(trial):\n  \n    params = {\n        'boosting_type': 'gbdt',\n        'n_estimators': trial.suggest_int('n_estimators', 500, 5000),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n        'num_leaves': trial.suggest_int('num_leaves', 32, 128),\n        'max_depth': trial.suggest_int('max_depth', 4, 12),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 10),\n        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),\n        'max_bin': trial.suggest_int('max_bin', 512, 4096)\n    }\n      \n    #scale_pos_weight = len(y[y == 0]) / len(y[y == 1])\n    model = lgb.LGBMClassifier(**params, objective='binary', metric='auc', is_unbalance=True, random_state=42, verbosity=-1)\n    # scale_pos_weight=scale_pos_weight) \n    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    \n    return cross_val_score(model, X, y, cv=cv, scoring='roc_auc').mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T17:11:27.442619Z","iopub.execute_input":"2025-08-08T17:11:27.443170Z","iopub.status.idle":"2025-08-08T17:11:27.451526Z","shell.execute_reply.started":"2025-08-08T17:11:27.443149Z","shell.execute_reply":"2025-08-08T17:11:27.450490Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Load data\ntrain = pd.read_csv('/kaggle/input/playground-series-s5e8/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s5e8/test.csv')\noriginal = pd.read_csv('/kaggle/input/bank-marketing-dataset-full/bank-full.csv', delimiter=\";\")\nsubmission = pd.read_csv('/kaggle/input/playground-series-s5e8/sample_submission.csv')\n\noriginal['y'] = original['y'].map({'yes': 1, 'no': 0})\n\ntrain = pd.concat([train, original], axis=0, ignore_index=True)\n\n# Features for training (drop id and target)\nX = train.drop(['id', 'y'], axis=1)\ny = train['y']\n\n# Features for test set (drop only id)\nX_test = test.drop(['id'], axis=1)\n\n# Encode object and category columns to ensure unique values are mapped\nfor col in X.select_dtypes(include=['object', 'category']).columns:\n    le = LabelEncoder()\n    le.fit(list(X[col].astype(str)) + list(X_test[col].astype(str)))\n    X[col] = le.transform(X[col].astype(str))\n    X_test[col] = le.transform(X_test[col].astype(str))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T17:11:27.453946Z","iopub.execute_input":"2025-08-08T17:11:27.454248Z","iopub.status.idle":"2025-08-08T17:11:40.436408Z","shell.execute_reply.started":"2025-08-08T17:11:27.454216Z","shell.execute_reply":"2025-08-08T17:11:40.435544Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Cross-validated LGBMClassifier\n\nif tune:\n    # Optuna Study\n    study = optuna.create_study(direction='maximize')\n    study.optimize(objective, n_trials=25, timeout=5400, show_progress_bar=True)\n    best_params = study.best_trial.params\n    print('Best Parameters:', best_params)\n    print('Best Trial:', study.best_trial)\n\nelse:\n    best_params = {\"n_estimators\": 10000, \"learning_rate\": 0.05, \"min_child_samples\": 9,\n                   \"subsample\": 0.8, \"colsample_bytree\": 0.5, \"num_leaves\": 100, \"max_depth\": 10,\n                   \"max_bin\": 4096, \"reg_alpha\": 0.79, \"reg_lambda\": 3}\n\n        \nclf = lgb.LGBMClassifier(**best_params, objective='binary', metric='auc', random_state=42, verbosity=-1)\nclf.fit(X, y)\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\ncv_scores = cross_val_score(clf, X, y, cv=cv, scoring='roc_auc')\n\nprint(\"ROC AUC scores (CV):\", cv_scores)\nprint(\"Mean ROC AUC:\", np.mean(cv_scores))\n\npreds = clf.predict_proba(X_test)[:, 1] ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T17:11:40.437330Z","iopub.execute_input":"2025-08-08T17:11:40.437590Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Final submission\nsubmission['y'] = preds\nsubmission.to_csv('submission.csv', index=False)\ndisplay(submission)\nprint('Submission file saved.')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}