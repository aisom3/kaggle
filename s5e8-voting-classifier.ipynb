{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91719,"databundleVersionId":12937777,"sourceType":"competition"},{"sourceId":9293783,"sourceType":"datasetVersion","datasetId":5626665}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Author: Aaron Isom\n# Kaggle Playground-Series-S5e8 - Binary Classification with a Bank Dataset\n# Voting Classifier using CatBoost, LGBM, and XGBoost\n\nfrom sklearn.ensemble import VotingClassifier\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport pandas as pd\nimport warnings\n\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-06T22:51:37.083191Z","iopub.execute_input":"2025-08-06T22:51:37.083778Z","iopub.status.idle":"2025-08-06T22:51:37.089826Z","shell.execute_reply.started":"2025-08-06T22:51:37.083718Z","shell.execute_reply":"2025-08-06T22:51:37.088823Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Load data\ntrain = pd.read_csv('/kaggle/input/playground-series-s5e8/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s5e8/test.csv')\noriginal = pd.read_csv('/kaggle/input/bank-marketing-dataset-full/bank-full.csv', delimiter=\";\")\nsubmission = pd.read_csv('/kaggle/input/playground-series-s5e8/sample_submission.csv')\n\noriginal['y'] = original['y'].replace({'yes': 1, 'no': 0})\n\ntrain = pd.concat([train, original], axis=0, ignore_index=True)\n\n# Features for training (drop id and target)\nX = train.drop(['id', 'y'], axis=1)\ny = train['y']\n\n# Features for test set (drop only id)\nX_test = test.drop(['id'], axis=1)\n\n# Encode object and category columns\nfor col in X.select_dtypes(include=['object', 'category']).columns:\n    le = LabelEncoder()\n    X[col] = le.fit_transform(X[col].astype(str))\n    X_test[col] = le.fit_transform(X_test[col].astype(str))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T22:51:37.091275Z","iopub.execute_input":"2025-08-06T22:51:37.091540Z","iopub.status.idle":"2025-08-06T22:51:41.885340Z","shell.execute_reply.started":"2025-08-06T22:51:37.091512Z","shell.execute_reply":"2025-08-06T22:51:41.884553Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Create three voting classifiers - CatBoost, LGBM, and XGBoost\nclf1 = LGBMClassifier(n_estimators=1000, objective='binary', random_state=42, metric='binary_logloss', verbose=-1)\nclf2 = XGBClassifier(n_estimators=1000, objective='binary:logistic', eval_metric='auc', random_state=42, n_jobs=-1, \n                          enable_categorical=True, tree_method='hist', verbose=-1)\nclf3 = CatBoostClassifier(n_estimators=1000, loss_function='Logloss', eval_metric='AUC', random_state=42, verbose=0)\n\nvoting_clf = VotingClassifier(estimators=[('lgbm', clf1), ('xgb', clf2), ('cat', clf3)], voting='soft')\nvoting_clf.fit(X, y)\n\npreds = voting_clf.predict_proba(X_test)[:, 1]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Final submission\nsubmission['y'] = preds\nsubmission.to_csv('submission.csv', index=False)\ndisplay(submission)\nprint('Submission file saved.')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}