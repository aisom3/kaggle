{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91719,"databundleVersionId":12937777,"sourceType":"competition"},{"sourceId":9293783,"sourceType":"datasetVersion","datasetId":5626665}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aaronisomaisom3/s5e8-voting-classifier?scriptVersionId=254828141\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# Author: Aaron Isom\n# Kaggle Playground-Series-S5e8 - Binary Classification with a Bank Dataset\n# Voting Classifier using CatBoost, LGBM, and XGBoost\n\nfrom sklearn.ensemble import VotingClassifier, HistGradientBoostingClassifier\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport pandas as pd\nimport warnings\n\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-07T17:47:09.256798Z","iopub.execute_input":"2025-08-07T17:47:09.257096Z","iopub.status.idle":"2025-08-07T17:47:12.055229Z","shell.execute_reply.started":"2025-08-07T17:47:09.257072Z","shell.execute_reply":"2025-08-07T17:47:12.054371Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Load data\ntrain = pd.read_csv('/kaggle/input/playground-series-s5e8/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s5e8/test.csv')\noriginal = pd.read_csv('/kaggle/input/bank-marketing-dataset-full/bank-full.csv', delimiter=\";\")\nsubmission = pd.read_csv('/kaggle/input/playground-series-s5e8/sample_submission.csv')\n\noriginal['y'] = original['y'].replace({'yes': 1, 'no': 0})\n\ntrain = pd.concat([train, original], axis=0, ignore_index=True)\n\n# Features for training (drop id and target)\nX = train.drop(['id', 'y'], axis=1)\ny = train['y']\n\n# Features for test set (drop only id)\nX_test = test.drop(['id'], axis=1)\n\n# Encode object and category columns to ensure unique values are mapped\nfor col in X.select_dtypes(include=['object', 'category']).columns:\n    le = LabelEncoder()\n    le.fit(list(X[col].astype(str)) + list(X_test[col].astype(str)))\n    X[col] = le.transform(X[col].astype(str))\n    X_test[col] = le.transform(X_test[col].astype(str))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T17:47:12.056604Z","iopub.execute_input":"2025-08-07T17:47:12.05731Z","iopub.status.idle":"2025-08-07T17:47:24.11764Z","shell.execute_reply.started":"2025-08-07T17:47:12.057282Z","shell.execute_reply":"2025-08-07T17:47:24.11675Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Create three voting classifiers - CatBoost, LGBM, XGBoost, and HGBT. Drop the lowest scoring model.\nscale_pos_weight = len(y[y == 0]) / len(y[y == 1])\n\nclf1 = LGBMClassifier(n_estimators=2000, objective='binary', random_state=42, metric='binary_logloss', verbose=0, scale_pos_weight=scale_pos_weight)\nclf2 = XGBClassifier(n_estimators=2000, objective='binary:logistic', eval_metric='auc', random_state=42, n_jobs=-1, \n                          enable_categorical=True, tree_method='hist', verbose=0, scale_pos_weight=scale_pos_weight)\nclf3 = CatBoostClassifier(n_estimators=2000, eval_metric='AUC', random_state=42, verbose=0, class_weights=[1, scale_pos_weight])\nclf4 = HistGradientBoostingClassifier(max_iter=2000, random_state=42, verbose=0, class_weight='balanced')\n\nmodels = [\n    ('lgbm', clf1),\n    ('xgb', clf2),\n    ('cat', clf3),\n    ('hgbt', clf4)\n]\n\nscores = {}\nfor name, model in models:\n    score = cross_val_score(model, X, y, cv=5, scoring='roc_auc').mean()\n    scores[name] = score\n    print(f\"{name} ROC-AUC: {score:.5f}\")\n\n\n# Sort by score and drop the lowest\nsorted_models = sorted(scores.items(), key=lambda x: x[1], reverse=True)\ntop3_names = [name for name, _ in sorted_models[:3]]\n\n# Filter the original models to keep only the top 3\nfinal_estimators = [item for item in models if item[0] in top3_names]\nprint(\"Top 3 models:\", top3_names)\n\nvoting_clf = VotingClassifier(estimators=final_estimators, voting='soft')\nvoting_clf.fit(X, y)\n\npreds = voting_clf.predict_proba(X_test)[:, 1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T17:47:24.118493Z","iopub.execute_input":"2025-08-07T17:47:24.118737Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Final submission\nsubmission['y'] = preds\nsubmission.to_csv('submission.csv', index=False)\ndisplay(submission)\nprint('Submission file saved.')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}